<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">TEG</title><meta name="description" content="A Reinforcement Learning enviroment for train agents in robot manipulation" data-next-head=""/><meta name="author" content="Alexis Fraudita" data-next-head=""/><meta name="keywords" content="Machine Learning, Robotics, Electronics, Reinforcement Learning, Blog, Portfolio, Alexis, Fraudita, Alexis Fraudita, Python, Pytorch" data-next-head=""/><meta property="title" content="TEG" data-next-head=""/><meta property="url" content="https://alefram.github.io/projects/TEG" data-next-head=""/><meta property="type" content="website" data-next-head=""/><meta name="viewport" content="initial-scale=1.0,  widt h=device-width" data-next-head=""/><meta name="robots" content="index, follow" data-next-head=""/><meta property="og:url" content="https://alefram.github.io/projects/TEG" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta property="og:title" content="TEG" data-next-head=""/><meta property="og:description" content="A Reinforcement Learning enviroment for train agents in robot manipulation" data-next-head=""/><meta property="og:image" content="üèì" data-next-head=""/><meta name="twitter:card" content="summary_short_image" data-next-head=""/><meta property="twitter:domain" content="alefram.github.io" data-next-head=""/><meta property="twitter:url" content="https://alefram.github.io/projects/TEG" data-next-head=""/><meta name="twitter:title" content="TEG" data-next-head=""/><meta name="twitter:description" content="A Reinforcement Learning enviroment for train agents in robot manipulation" data-next-head=""/><meta name="twitter:image" content="üèì" data-next-head=""/><link rel="canonical" href="https://alefram.github.io/"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="https://fonts.googleapis.com/css2?family=Square+Peg&amp;display=swap" rel="stylesheet"/><meta name="robots" content="index, follow"/><link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;üèì&lt;/text&gt;&lt;/svg&gt;"/><link rel="manifest" href="/site.webmanifest"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"/><meta name="google-site-verification" content="MpnKrcQvKDGeW2EIhtOow24kp2VahB-vL2hYzqGNC54"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PHJRD3DMEN"></script><script>
                        window.dataLayer = window.dataLayer || [];
                        function gtag(){dataLayer.push(arguments);}
                        gtag('js', new Date());
                        gtag('config', 'G-PHJRD3DMEN', {
                        page_path: window.location.pathname
                        });
                    </script><link rel="preload" href="/_next/static/chunks/bba72d2c6648da79.css" as="style"/><link rel="stylesheet" href="/_next/static/chunks/bba72d2c6648da79.css" data-n-g=""/><noscript data-n-css=""></noscript><script src="/_next/static/chunks/3afb1dc2b4a44014.js" defer=""></script><script src="/_next/static/chunks/6227e15e560aba77.js" defer=""></script><script src="/_next/static/chunks/dbb56e797ef6164c.js" defer=""></script><script src="/_next/static/chunks/e53392f7a16613bc.js" defer=""></script><script src="/_next/static/chunks/turbopack-8b111ceebb25e3a4.js" defer=""></script><script src="/_next/static/chunks/a8a575a1123f0947.js" defer=""></script><script src="/_next/static/chunks/509f79bf4745ce0c.js" defer=""></script><script src="/_next/static/chunks/turbopack-9db5b72767d250d5.js" defer=""></script><script src="/_next/static/2_evnEjvgUVWGtJgC_C87/_ssgManifest.js" defer=""></script><script src="/_next/static/2_evnEjvgUVWGtJgC_C87/_buildManifest.js" defer=""></script></head><body><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div><nav><div class="flex flex-col md:flex-row p-2 container mx-auto  lg:max-w-screen-lg justify-between md:items-center"><div class="mt-1 flex space-x-2"><a class="text-neutral-900 dark:text-neutral-100 font-bold text-4xl font-square-peg" href="/">üèì AleBlog</a><button><img loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="my-auto" style="color:transparent" src="/images/dark.svg"/></button></div><div class="mt-2 md:m-2 md:p-4 space-x-4 md:text-center"><a class="text-neutral-900 font-bold hover:underline hover:text-blue-600 font-nunito dark:text-neutral-100 dark:hover:text-blue-300" href="/Projects">Projects</a><a class="text-neutral-900 font-bold hover:underline hover:text-blue-600 font-nunito dark:text-neutral-100 dark:hover:text-blue-300" href="/Software">Software</a><a class="text-neutral-900 font-bold hover:underline hover:text-blue-600 font-nunito dark:text-neutral-100 dark:hover:text-blue-300" href="/About">About</a></div></div></nav><main class="mt-10 px-4 md:px-2 "><div class="mx-auto max-w-2xl"><h1 class="text-2xl md:text-4xl text-neutral-900  dark:text-neutral-100 font-bold font-nunito">TEG</h1><article class="text-base max-w-2xl mt-10 font-Roboto markdown prose  prose-blue text-neutral-800 dark:text-neutral-400 dark:prose-invert"><p>TEG is a Reinforcement Learning enviroment, for training AI agents.
This project started as my Bachelor thesis in Electrical Engineer but I have
the intention of continue it and add more features that I hope would be usefull
for Developers and Researchers.</p>
<h2>Features</h2>
<ul>
<li>Reinforcement Learning enviroment for a single AI agent.</li>
<li>Robot Models (Currently UR5 only).</li>
</ul>
<h2>Resources</h2>
<p>Some of the resources that I have used to create this project are:</p>
<ul>
<li><a href="https://github.com/openai/gym">OpenAI Gym</a></li>
<li><a href="https://mujoco.org/">Mujoco</a></li>
<li><a href="https://github.com/openai/mujoco-py">Mujoco py</a></li>
<li><a href="https://github.com/roboticsleeds/mujoco-ur5-model">UR5</a></li>
</ul>
<p>If you want to see more information about this project, you can visit my
<a href="www.github.com/Alefram/TEG"><em>GitHub</em></a>, I hope it would be usefull for you.</p></article></div></main><footer class="py-12"><div class="flex justify-center space-x-4 mt-4"><a href="https://github.com/alefram"><img alt="githubFooter" src="/images/github.svg" class="w-8"/></a><a href="https://x.com/_Alefram_"><img alt="XFooter" src="/images/x.svg" class="w-8"/></a></div><div class="text-center text-lg text-neutral-900 dark:text-neutral-100"><small>Make with üíô ¬©<!-- -->2025<!-- --> All rights reserved</small></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"projectData":{"id":"TEG","contentHtml":"\u003cp\u003eTEG is a Reinforcement Learning enviroment, for training AI agents.\nThis project started as my Bachelor thesis in Electrical Engineer but I have\nthe intention of continue it and add more features that I hope would be usefull\nfor Developers and Researchers.\u003c/p\u003e\n\u003ch2\u003eFeatures\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eReinforcement Learning enviroment for a single AI agent.\u003c/li\u003e\n\u003cli\u003eRobot Models (Currently UR5 only).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eResources\u003c/h2\u003e\n\u003cp\u003eSome of the resources that I have used to create this project are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/openai/gym\"\u003eOpenAI Gym\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mujoco.org/\"\u003eMujoco\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/openai/mujoco-py\"\u003eMujoco py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/roboticsleeds/mujoco-ur5-model\"\u003eUR5\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you want to see more information about this project, you can visit my\n\u003ca href=\"www.github.com/Alefram/TEG\"\u003e\u003cem\u003eGitHub\u003c/em\u003e\u003c/a\u003e, I hope it would be usefull for you.\u003c/p\u003e","title":"TEG","description":"A Reinforcement Learning enviroment for train agents in robot manipulation","image":"images/projects/TEG.png","altImage":"TEG","keywords":"Machine Learning, Robotics, Electronics, Reinforcement Learning, Blog, Portfolio, Alexis, Fraudita, Alexis Fraudita, Python, Pytorch"}},"__N_SSG":true},"page":"/projects/[id]","query":{"id":"TEG"},"buildId":"2_evnEjvgUVWGtJgC_C87","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>